{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('gp_env': venv)"
  },
  "interpreter": {
   "hash": "97db42803fcebb1c54788cb8eb690d6a415f39d32f595e24dbe1c0683e9170ed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.4 Prepare Network Analysis Dataset\r\n",
    "\r\n",
    "This is the fourth part of our complete workflow. We use the subreddit dataset to generate a relationship table. The relationship table contains information regarding the \"parent\" thread and the \"child\" response, which is a response to the corresponding \"parent\" thread.\r\n",
    "\r\n",
    "When we analyze the processed dataset using KNIME, we will only use the columns creator_id and replier_id.\r\n",
    "\r\n",
    "At the end of the workflow, the dataset will contain the following columns:\r\n",
    "- parent_thread_id\r\n",
    "- thread_creation_date\r\n",
    "- post_id\r\n",
    "- post_creation_date\r\n",
    "- creator_id\r\n",
    "- replier_id\r\n",
    "- pos_emo\r\n",
    "- neg_emo\r\n",
    "\r\n",
    "Please note that you should execute the `2-social-network-analysis-workflow.knwf` KNIME workflow after executing this notebook and before executing `1-5-social-network-analysis.ipynb`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# !pip install pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "reddit_df = pd.read_csv('../original-datasets/RedditCrypto-2017.csv', header=0, names=['parent_thread_id', 'post_id', 'user_id', 'timestamp', 'pos_emo', 'neg_emo'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Process data for social network analysis"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove leading and trailing white space"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "reddit_df['parent_thread_id'] = reddit_df['parent_thread_id'].str.strip()\r\n",
    "reddit_df['post_id'] = reddit_df['post_id'].str.strip()\r\n",
    "reddit_df['user_id'] = reddit_df['user_id'].str.strip()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract thread id from file name"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "reddit_df['parent_thread_id'] = reddit_df['parent_thread_id'].str.slice(start=15, stop=21)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dataframe with only \"parent\" posts"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "creator_posts_df = reddit_df[reddit_df['post_id'] == reddit_df['parent_thread_id']]\r\n",
    "creator_posts_df = creator_posts_df.rename(columns={'user_id': 'creator_id', 'timestamp': 'thread_creation_date'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Join the \"parent posts\" dataframe with the original dataset\n",
    "\n",
    "Match each post in the complete dataset with its corresponding \"parent post\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "joined_posts_df = creator_posts_df.merge(reddit_df, left_on='post_id', right_on='parent_thread_id')\r\n",
    "joined_posts_df.drop(['post_id_x', 'pos_emo_x', 'neg_emo_x', 'parent_thread_id_y'], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove tuples with the same creator_id and user_id"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "joined_posts_df = joined_posts_df[joined_posts_df['creator_id'] != joined_posts_df['user_id']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove tuples where at least one of the users involved are bots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "joined_posts_df = joined_posts_df[joined_posts_df['creator_id'] != 'AutoModerator']\r\n",
    "joined_posts_df = joined_posts_df[joined_posts_df['creator_id'] != 'None']\r\n",
    "joined_posts_df = joined_posts_df[joined_posts_df['user_id'] != 'None']\r\n",
    "joined_posts_df = joined_posts_df[joined_posts_df['user_id'] != 'AutoModerator']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rename columns for clarity"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "joined_posts_df = joined_posts_df.rename(\r\n",
    "    columns={\r\n",
    "        'parent_thread_id_x': 'parent_thread_id', \r\n",
    "        'post_id_y': 'post_id', \r\n",
    "        'timestamp': 'post_creation_date', \r\n",
    "        'pos_emo_y': 'pos_emo', \r\n",
    "        'neg_emo_y': 'neg_emo',\r\n",
    "        'user_id': 'replier_id'\r\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reorder columns"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "joined_posts_df = joined_posts_df[['parent_thread_id', 'thread_creation_date', 'post_id', 'post_creation_date', 'creator_id', 'replier_id', 'pos_emo', 'neg_emo']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Export datasets to csv"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "joined_posts_df.to_csv('../generated-datasets/network-analysis-dataset.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}