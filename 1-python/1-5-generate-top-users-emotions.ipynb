{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1.5 Generate top users emotion attribute\r\n",
    "\r\n",
    "This is the final part of our complete workflow. Using the output from KNIME, we determine the dominating emotion for all posts made by the top 3 most influential subreddit users, for each day.\r\n",
    "\r\n",
    "Neutral days are assigned a 0, positive days are assigned a 1, and negative days are assigned a -1.\r\n",
    "\r\n",
    "If none of the top users had made a post on a particular day, we assume the emotion is neutral, and label the corresponding date as 0.\r\n",
    "\r\n",
    "\r\n",
    "At the end of the workflow, the dataset will contain the following columns:\r\n",
    "- Date\r\n",
    "- is_profitable\r\n",
    "- close-low\r\n",
    "- close-high\r\n",
    "- SMA-close\r\n",
    "- EMA-close\r\n",
    "- EMA_diff\r\n",
    "- SMA_diff\r\n",
    "- pos_emo\r\n",
    "- neg_emo\r\n",
    "- top_influencer_emotion\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# !pip install pandas"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def determine_emotion(row):\r\n",
    "    if row['pos_emo_y'] > row['neg_emo_y']:\r\n",
    "        row['top_influencer_emotion'] = 1\r\n",
    "    elif row['pos_emo_y'] < row['neg_emo_y']:\r\n",
    "        row['top_influencer_emotion'] = -1\r\n",
    "    else:\r\n",
    "        row['top_influencer_emotion'] = 0\r\n",
    "    return row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import and preprocess datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "influencers_df = pd.read_csv('../generated-datasets/top-influencers.csv', usecols=['Object id']).head(3)\r\n",
    "\r\n",
    "reddit_df = pd.read_csv('../original-datasets/RedditCrypto-2017.csv', header=0, usecols=['Source (C)', 'Source (E)', 'posemo', 'negemo'])\r\n",
    "reddit_df = reddit_df.rename(columns={'Source (C)': 'poster', 'Source (E)':'timestamp', 'posemo': 'pos_emo', 'negemo': 'neg_emo'})\r\n",
    "reddit_df['poster'] = reddit_df['poster'].str.strip()\r\n",
    "\r\n",
    "processed_reddit_df = pd.read_csv('../generated-datasets/classification-dataset-with-emotion-scores.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop posts that are not by top influencers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "reddit_df = reddit_df.merge(right=influencers_df, left_on='poster', right_on='Object id')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take aggreagate sum of each day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "reddit_df['timestamp'] = pd.to_datetime(reddit_df['timestamp'])\r\n",
    "reddit_df['timestamp'] = reddit_df['timestamp'].dt.date\r\n",
    "\r\n",
    "reddit_df = reddit_df.groupby(['timestamp'], as_index=False).sum()\r\n",
    "reddit_df['timestamp'] = pd.to_datetime(reddit_df['timestamp'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Join top influencer posts with other daily statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "processed_reddit_df['Date'] = pd.to_datetime(processed_reddit_df['Date'])\r\n",
    "\r\n",
    "processed_reddit_df = pd.merge(processed_reddit_df, reddit_df, how='left', left_on=[\"Date\"], right_on=[\"timestamp\"], sort=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create column indicating the dominating emotion of the posts from the top influencers for each day"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "processed_reddit_df = processed_reddit_df.apply(determine_emotion, axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Drop unused columns and rename column headers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "processed_reddit_df = processed_reddit_df.drop(columns=['Unnamed: 0', 'timestamp', 'pos_emo_y', 'neg_emo_y'])\r\n",
    "processed_reddit_df = processed_reddit_df.rename(columns={'pos_emo_x': 'pos_emo', 'neg_emo_x': 'neg_emo'})\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Export dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "processed_reddit_df.to_csv('../generated-datasets/classification-dataset-with-emotion-scores.csv')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('test_env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "207a1d4264d7b30b581ef8e9e1fab3771fe2b2daf687a49f3b6a80360b97736a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}